{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл с аккаунтами: out/risk_accounts_min_metrics.csv\n",
      "Файл с менеджерами: out/summary_by_manager.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "IN_CSV = Path(\"final_data.csv\")                \n",
    "OUT_DIR = Path(\"out\")                     \n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_ACCOUNTS = OUT_DIR / \"risk_accounts_min_metrics.csv\"\n",
    "OUT_MANAGERS = OUT_DIR / \"summary_by_manager.csv\"\n",
    "\n",
    "df = pd.read_csv(IN_CSV)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "num_cols = [\n",
    "    \"cal_health_factor_scaled\",\n",
    "    \"cal_health_factor\",\n",
    "    \"cal_borrowed_amt_with_interest\",\n",
    "    \"borrowed_amt_with_interest_usd\",\n",
    "    \"cal_total_value\",\n",
    "    \"total_value_usd\",\n",
    "    \"underlying_price_usd\",\n",
    "    \"available_liquidity_underlying\",\n",
    "    \"available_liquidity_usd\",\n",
    "    \"base_borrow_apy\",\n",
    "    \"leverage\",\n",
    "]\n",
    "for c in num_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Производные поля\n",
    "if \"cal_health_factor_scaled\" in df.columns:\n",
    "    df[\"hf_raw\"] = df[\"cal_health_factor_scaled\"] / 10000.0\n",
    "elif \"cal_health_factor\" in df.columns:\n",
    "    df[\"hf_raw\"] = df[\"cal_health_factor\"] / 10000.0\n",
    "\n",
    "if \"leverage\" in df.columns:\n",
    "    df[\"leverage_x\"] = df[\"leverage\"] / 100.0\n",
    "\n",
    "if \"base_borrow_apy\" in df.columns:\n",
    "    df[\"borrow_rate_annual\"] = df[\"base_borrow_apy\"] / 100.0\n",
    "\n",
    "if \"borrowed_amt_with_interest_usd\" not in df.columns:\n",
    "    if \"cal_borrowed_amt_with_interest\" in df.columns and \"underlying_price_usd\" in df.columns:\n",
    "        df[\"borrowed_amt_with_interest_usd\"] = (\n",
    "            df[\"cal_borrowed_amt_with_interest\"] * df[\"underlying_price_usd\"]\n",
    "        )\n",
    "\n",
    "if \"available_liquidity_usd\" not in df.columns:\n",
    "    if \"available_liquidity_underlying\" in df.columns and \"underlying_price_usd\" in df.columns:\n",
    "        df[\"available_liquidity_usd\"] = (\n",
    "            df[\"available_liquidity_underlying\"] * df[\"underlying_price_usd\"]\n",
    "        )\n",
    "\n",
    "df[\"liq_gap_usd\"] = np.maximum(\n",
    "    0.0,\n",
    "    df.get(\"borrowed_amt_with_interest_usd\", np.nan)\n",
    "    - df.get(\"available_liquidity_usd\", np.nan),\n",
    ")\n",
    "df[\"liq_gap_underlying\"] = np.maximum(\n",
    "    0.0,\n",
    "    df.get(\"cal_borrowed_amt_with_interest\", np.nan)\n",
    "    - df.get(\"available_liquidity_underlying\", np.nan),\n",
    ")\n",
    "\n",
    "if \"hf_raw\" in df.columns:\n",
    "    df = df[df[\"hf_raw\"] <= 1.10].copy()\n",
    "\n",
    "account_cols = [\n",
    "    \"session_id\",\n",
    "    \"account\",\n",
    "    \"credit_manager\",\n",
    "    \"since_timestamp\",\n",
    "    \"cal_health_factor_scaled\",\n",
    "    \"hf_raw\",\n",
    "    \"cal_borrowed_amt_with_interest\",\n",
    "    \"borrowed_amt_with_interest_usd\",\n",
    "    \"cal_total_value\",\n",
    "    \"total_value_usd\",\n",
    "    \"leverage\",\n",
    "    \"leverage_x\",\n",
    "    \"underlying_token\",\n",
    "    \"underlying_price_usd\",\n",
    "    \"available_liquidity_underlying\",\n",
    "    \"available_liquidity_usd\",\n",
    "    \"liq_gap_underlying\",\n",
    "    \"liq_gap_usd\",\n",
    "    \"base_borrow_apy\",\n",
    "    \"borrow_rate_annual\",\n",
    "]\n",
    "account_cols = [c for c in account_cols if c in df.columns]\n",
    "df_accounts = df[account_cols].sort_values([\"hf_raw\", \"total_value_usd\"], ascending=[True, False])\n",
    "df_accounts.to_csv(OUT_ACCOUNTS, index=False)\n",
    "\n",
    "# По менеджерам \n",
    "group_cols = [\"credit_manager\"]\n",
    "agg = {\"session_id\": \"count\"}\n",
    "for c in [\n",
    "    \"hf_raw\",\n",
    "    \"borrowed_amt_with_interest_usd\",\n",
    "    \"available_liquidity_usd\",\n",
    "    \"liq_gap_usd\",\n",
    "    \"base_borrow_apy\",\n",
    "    \"borrow_rate_annual\",\n",
    "]:\n",
    "    if c in df.columns:\n",
    "        if c == \"hf_raw\":\n",
    "            agg[c] = [\"min\", \"median\"]\n",
    "        elif c in (\"base_borrow_apy\", \"borrow_rate_annual\"):\n",
    "            agg[c] = \"median\"\n",
    "        else:\n",
    "            agg[c] = \"sum\"\n",
    "\n",
    "g = df.groupby(group_cols, dropna=False).agg(agg)\n",
    "g.columns = [\"_\".join(col) if isinstance(col, tuple) else col for col in g.columns]\n",
    "g = g.reset_index()\n",
    "\n",
    "rename_map = {\n",
    "    \"session_id_count\": \"risky_accounts\",\n",
    "    \"hf_raw_min\": \"hf_min\",\n",
    "    \"hf_raw_median\": \"hf_median\",\n",
    "    \"borrowed_amt_with_interest_usd_sum\": \"debt_usd_sum\",\n",
    "    \"available_liquidity_usd_sum\": \"available_liquidity_usd_sum\",\n",
    "    \"liq_gap_usd_sum\": \"liq_gap_usd_sum\",\n",
    "    \"base_borrow_apy_median\": \"base_borrow_apy_median\",\n",
    "    \"borrow_rate_annual_median\": \"borrow_rate_annual_median\",\n",
    "}\n",
    "g = g.rename(columns=rename_map)\n",
    "\n",
    "sort_cols = [c for c in [\"liq_gap_usd_sum\", \"debt_usd_sum\"] if c in g.columns]\n",
    "if sort_cols:\n",
    "    g = g.sort_values(sort_cols, ascending=[False] * len(sort_cols))\n",
    "\n",
    "g.to_csv(OUT_MANAGERS, index=False)\n",
    "\n",
    "print(f\"Файл с аккаунтами: {OUT_ACCOUNTS}\")\n",
    "print(f\"Файл с менеджерами: {OUT_MANAGERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done. All outputs saved in: /Users/phlxndr/Desktop/GearBox/September/results\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from textwrap import shorten\n",
    "\n",
    "IN_ACCOUNTS = Path(\"out/risk_accounts_min_metrics.csv\")\n",
    "IN_MANAGERS = Path(\"out/summary_by_manager.csv\") \n",
    "TOKENS_ALIASES = Path(\"out/tokens_aliases.csv\")   \n",
    "MANAGER_ALIASES = Path(\"out/manager_aliases.csv\")  \n",
    "RESULTS = Path(\"results\")\n",
    "RESULTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_acc = pd.read_csv(IN_ACCOUNTS)\n",
    "if IN_MANAGERS.exists():\n",
    "    _df_man_unused = pd.read_csv(IN_MANAGERS)\n",
    "\n",
    "def short_addr(a: str) -> str:\n",
    "    a = str(a) if pd.notna(a) else \"\"\n",
    "    return f\"{a[:6]}…{a[-4:]}\" if len(a) >= 10 else a\n",
    "\n",
    "token_map = {}\n",
    "if TOKENS_ALIASES.exists():\n",
    "    tdf = pd.read_csv(TOKENS_ALIASES)\n",
    "    if {\"address\",\"symbol\"}.issubset(tdf.columns):\n",
    "        token_map = dict(zip(tdf[\"address\"].astype(str).str.lower(), tdf[\"symbol\"].astype(str)))\n",
    "\n",
    "manager_map = {}\n",
    "if MANAGER_ALIASES.exists():\n",
    "    mdf = pd.read_csv(MANAGER_ALIASES)\n",
    "    if {\"credit_manager\",\"label\"}.issubset(mdf.columns):\n",
    "        manager_map = dict(zip(mdf[\"credit_manager\"].astype(str).str.lower(), mdf[\"label\"].astype(str)))\n",
    "\n",
    "if \"underlying_token\" in df_acc.columns:\n",
    "    df_acc[\"underlying_symbol\"] = df_acc[\"underlying_token\"].astype(str).str.lower().map(token_map)\n",
    "    df_acc[\"underlying_symbol\"] = df_acc[\"underlying_symbol\"].fillna(df_acc[\"underlying_token\"].astype(str).map(short_addr))\n",
    "else:\n",
    "    df_acc[\"underlying_symbol\"] = \"UNKNOWN\"\n",
    "\n",
    "if \"credit_manager\" in df_acc.columns:\n",
    "    df_acc[\"manager_label\"] = df_acc[\"credit_manager\"].astype(str).str.lower().map(manager_map)\n",
    "    df_acc[\"manager_label\"] = df_acc[\"manager_label\"].fillna(df_acc[\"credit_manager\"].astype(str).map(short_addr))\n",
    "else:\n",
    "    df_acc[\"manager_label\"] = \"UNKNOWN\"\n",
    "\n",
    "# -------------------------\n",
    "# 1) Time-to-Liq (risk metric)\n",
    "# -------------------------\n",
    "for c in [\"hf_raw\",\"borrow_rate_annual\",\"borrowed_amt_with_interest_usd\",\"total_value_usd\"]:\n",
    "    if c in df_acc.columns:\n",
    "        df_acc[c] = pd.to_numeric(df_acc[c], errors=\"coerce\")\n",
    "\n",
    "df_acc[\"time_to_liq_days\"] = np.where(\n",
    "    (df_acc[\"borrow_rate_annual\"] > 0) & (df_acc[\"hf_raw\"] > 1),\n",
    "    np.log(df_acc[\"hf_raw\"]) / df_acc[\"borrow_rate_annual\"] * 365.0,\n",
    "    np.inf\n",
    ")\n",
    "\n",
    "# --- Borrow-rate shock scenarios (TtL under higher borrow APY) ---\n",
    "RATE_SHOCKS = {\n",
    "    \"r_p25\": 1.25,   # +25%\n",
    "    \"r_p50\": 1.50,   # +50%\n",
    "    \"r_x2\":  2.00,   # ×2\n",
    "    \"r_x4\":  4.00,   # ×4\n",
    "}\n",
    "\n",
    "def ttl_given_rate(df, factor):\n",
    "    br = pd.to_numeric(df[\"borrow_rate_annual\"], errors=\"coerce\")\n",
    "    hf = pd.to_numeric(df[\"hf_raw\"], errors=\"coerce\")\n",
    "    ttl = np.where((br > 0) & (hf > 1), np.log(hf)/(br*factor)*365.0, 0.0)\n",
    "    ttl = np.clip(ttl, 0, np.inf)  # отрицательные в 0\n",
    "    return ttl\n",
    "\n",
    "RATE_TTL_COLS = [] \n",
    "for tag, fac in RATE_SHOCKS.items():\n",
    "    col = f\"time_to_liq_days__{tag}\"\n",
    "    df_acc[col] = ttl_given_rate(df_acc, fac)\n",
    "    RATE_TTL_COLS.append(col)\n",
    "\n",
    "# -------------------------\n",
    "# 2) Price stress tests: −5, −10, −15, −20 %\n",
    "# -------------------------\n",
    "SCENARIOS = [-0.05, -0.10, -0.15, -0.20]\n",
    "\n",
    "def stress_hf(df, shock):\n",
    "    new_tv = df[\"total_value_usd\"] * (1.0 + shock)\n",
    "    return new_tv / df[\"borrowed_amt_with_interest_usd\"]\n",
    "\n",
    "for s in SCENARIOS:\n",
    "    tag = f\"{int(abs(s)*100)}\"\n",
    "    df_acc[f\"hf_stress_{tag}\"] = stress_hf(df_acc, s)\n",
    "    df_acc[f\"liq_flag_{tag}\"]  = df_acc[f\"hf_stress_{tag}\"] < 1.0\n",
    "    df_acc[f\"dar_{tag}_usd\"]   = np.where(df_acc[f\"liq_flag_{tag}\"],\n",
    "                                          df_acc[\"borrowed_amt_with_interest_usd\"], 0.0)\n",
    "\n",
    "# -------------------------\n",
    "# 3) Manager-level stats (group BY readable manager_label)\n",
    "# -------------------------\n",
    "group_cols = [\"manager_label\"] \n",
    "agg = {\n",
    "    \"account\": \"count\",\n",
    "    \"borrowed_amt_with_interest_usd\": \"sum\",\n",
    "    \"available_liquidity_usd\": \"sum\",\n",
    "    \"hf_raw\": [\"min\", \"median\"],\n",
    "    \"time_to_liq_days\": [\"median\"]\n",
    "}\n",
    "for s in SCENARIOS:\n",
    "    agg[f\"liq_flag_{int(abs(s)*100)}\"] = \"sum\"\n",
    "    agg[f\"dar_{int(abs(s)*100)}_usd\"] = \"sum\"\n",
    "\n",
    "g = df_acc.groupby(group_cols, dropna=False).agg(agg)\n",
    "g.columns = [\"_\".join(c) if isinstance(c, tuple) else c for c in g.columns]\n",
    "g = g.rename(columns={\n",
    "    \"account_count\": \"risky_accounts\",\n",
    "    \"borrowed_amt_with_interest_usd_sum\": \"debt_usd_sum\",\n",
    "    \"available_liquidity_usd_sum\": \"available_liquidity_usd_sum\",\n",
    "    \"hf_raw_min\": \"hf_min\",\n",
    "    \"hf_raw_median\": \"hf_median\",\n",
    "    \"time_to_liq_days_median\": \"tli_median_days\",\n",
    "}).reset_index()\n",
    "\n",
    "for d in [7, 30, 90]:\n",
    "    g[f\"tli_le_{d}_count\"] = (\n",
    "        df_acc.assign(_f=(df_acc[\"time_to_liq_days\"] <= d))\n",
    "             .groupby(\"manager_label\")[\"_f\"].sum()\n",
    "             .reindex(g[\"manager_label\"]).fillna(0).astype(int).values\n",
    "    )\n",
    "\n",
    "for a,b,name in [(\"liq_flag_10_sum\",\"liq_flag_5_sum\",\"incr_10_vs_5\"),\n",
    "                 (\"liq_flag_15_sum\",\"liq_flag_10_sum\",\"incr_15_vs_10\"),\n",
    "                 (\"liq_flag_20_sum\",\"liq_flag_15_sum\",\"incr_20_vs_15\")]:\n",
    "    g[name] = (g.get(a,0) - g.get(b,0)) if (a in g.columns and b in g.columns) else 0\n",
    "\n",
    "g_rate = (\n",
    "    df_acc.groupby(\"manager_label\", dropna=False)[RATE_TTL_COLS]\n",
    "          .median()\n",
    "          .reset_index()\n",
    ")\n",
    "g = g.merge(g_rate, on=\"manager_label\", how=\"left\")\n",
    "\n",
    "rate_cols_order = [f\"time_to_liq_days__{k}\" for k in RATE_SHOCKS.keys()]\n",
    "for rc in rate_cols_order[::-1]:\n",
    "    if rc in g.columns:\n",
    "        cols = list(g.columns)\n",
    "        cols.insert(cols.index(\"tli_median_days\")+1, cols.pop(cols.index(rc)))\n",
    "        g = g[cols]\n",
    "\n",
    "g.to_csv(RESULTS / \"manager_stats.csv\", index=False)\n",
    "\n",
    "# -------------------------\n",
    "# 4) Account-level stats summary (descriptive)\n",
    "# -------------------------\n",
    "acc_stats = []\n",
    "def add_stat(name,val): acc_stats.append({\"metric\":name, \"value\":val})\n",
    "\n",
    "tfinite = df_acc[\"time_to_liq_days\"].replace(np.inf, np.nan).dropna()\n",
    "for q in [0.1,0.25,0.5,0.75,0.9]:\n",
    "    add_stat(f\"tli_days_p{int(q*100)}\", float(np.quantile(tfinite, q)) if len(tfinite) else np.nan)\n",
    "for d in [7,30,90]:\n",
    "    m = df_acc[\"time_to_liq_days\"] <= d\n",
    "    add_stat(f\"tli_days_<=_{d}_count\", int(m.sum()))\n",
    "    add_stat(f\"tli_days_<=_{d}_debt_usd\", float(df_acc.loc[m, \"borrowed_amt_with_interest_usd\"].sum()))\n",
    "for q in [0.1,0.25,0.5,0.75,0.9]:\n",
    "    add_stat(f\"hf_p{int(q*100)}\", float(np.quantile(df_acc[\"hf_raw\"], q)))\n",
    "for q in [0.5,0.75,0.9,0.95]:\n",
    "    add_stat(f\"debt_usd_p{int(q*100)}\", float(np.quantile(df_acc[\"borrowed_amt_with_interest_usd\"], q)))\n",
    "add_stat(\"debt_usd_sum\", float(df_acc[\"borrowed_amt_with_interest_usd\"].sum()))\n",
    "pd.DataFrame(acc_stats).to_csv(RESULTS / \"account_stats.csv\", index=False)\n",
    "\n",
    "# -------------------------\n",
    "# 5) Top-10 most urgent accounts (by shortest TtL)\n",
    "# -------------------------\n",
    "top10 = df_acc.sort_values(\"time_to_liq_days\", ascending=True).head(10).copy()\n",
    "top10.to_csv(RESULTS / \"top10_urgent_accounts.csv\", index=False)\n",
    "\n",
    "# -------------------------\n",
    "# 6) Figures (English labels; log-axis for Debt where needed)\n",
    "# -------------------------\n",
    "plt.rcParams.update({\"figure.dpi\": 130})\n",
    "\n",
    "# A) Top-10 by TtL\n",
    "plt.figure(figsize=(12,6))\n",
    "y = np.arange(len(top10))\n",
    "vals = top10[\"time_to_liq_days\"].values\n",
    "plt.barh(y, vals)\n",
    "for i,(t,hf,debt) in enumerate(zip(vals, top10[\"hf_raw\"], top10[\"borrowed_amt_with_interest_usd\"])):\n",
    "    plt.text(t, i, f\"  HF={hf:.3f}, Debt={debt/1e6:.2f}M\", va=\"center\", ha=\"left\")\n",
    "plt.yticks(y, [shorten(a, 38, placeholder=\"…\") for a in top10[\"account\"]])\n",
    "plt.xlabel(\"Time to liquidation (days) — lower is worse\")\n",
    "plt.title(\"Top-10 Most Urgent Accounts (by Time-to-Liq)\")\n",
    "plt.tight_layout(); plt.savefig(RESULTS/\"top10_time_to_liq.png\"); plt.close()\n",
    "\n",
    "# B) Liquidations under shocks\n",
    "labels = [\"Base\"] + [f\"-{int(abs(s)*100)}%\" for s in SCENARIOS]\n",
    "vals   = [int((df_acc[\"hf_raw\"]<1.0).sum())] + [int(df_acc[f\"liq_flag_{int(abs(s)*100)}\"].sum()) for s in SCENARIOS]\n",
    "plt.figure(figsize=(9,6)); x = np.arange(len(labels))\n",
    "plt.bar(x, vals)\n",
    "for xi,v in zip(x,vals):\n",
    "    plt.text(xi, v + (max(vals)*0.02 if max(vals) else 0.5), str(v), ha=\"center\", va=\"bottom\")\n",
    "plt.xticks(x, labels); plt.ylabel(\"Number of Accounts\"); plt.title(\"Liquidations under Price Shocks\")\n",
    "plt.tight_layout(); plt.savefig(RESULTS/\"stress_liquidations.png\"); plt.close()\n",
    "\n",
    "# C) Scatter: HF vs Debt (Debt axis log)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(df_acc[\"hf_raw\"], df_acc[\"borrowed_amt_with_interest_usd\"]/1e6, s=18, alpha=0.7)\n",
    "plt.yscale(\"log\"); plt.xlabel(\"Health Factor (normalized)\"); plt.ylabel(\"Debt (USD Millions, log scale)\")\n",
    "plt.title(\"HF vs Debt (Debt axis on log scale)\")\n",
    "plt.tight_layout(); plt.savefig(RESULTS/\"scatter_hf_debt.png\"); plt.close()\n",
    "\n",
    "# D) Scatter: Debt vs Time-to-Liq (Debt axis log)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(df_acc[\"borrowed_amt_with_interest_usd\"]/1e6, df_acc[\"time_to_liq_days\"], s=18, alpha=0.7)\n",
    "plt.xscale(\"log\"); plt.xlabel(\"Debt (USD Millions, log scale)\"); plt.ylabel(\"Time to liquidation (days)\")\n",
    "plt.title(\"Debt vs Time-to-Liq\")\n",
    "plt.tight_layout(); plt.savefig(RESULTS/\"scatter_debt_tli.png\"); plt.close()\n",
    "\n",
    "# E) Time-to-Liq distribution (linear)\n",
    "finite = df_acc[\"time_to_liq_days\"].replace(np.inf, np.nan).dropna()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(finite, bins=100)\n",
    "plt.xlabel(\"Time to liquidation (days)\"); plt.ylabel(\"Number of Accounts\")\n",
    "plt.title(\"Distribution of Time-to-Liq\")\n",
    "plt.tight_layout(); plt.savefig(RESULTS/\"time_to_liq_distribution.png\"); plt.close()\n",
    "\n",
    "# E2) TtL distribution (0–730 days, 14-day bins; Y = debt in USD millions) — FIXED\n",
    "mask_0_730 = (df_acc[\"time_to_liq_days\"] >= 0) & (df_acc[\"time_to_liq_days\"] <= 730)\n",
    "subset_0_730 = df_acc.loc[mask_0_730].copy()\n",
    "edges_14d = np.arange(0, 730 + 14, 14)\n",
    "cats_14d = pd.IntervalIndex.from_breaks(edges_14d, closed=\"left\")\n",
    "subset_0_730[\"tli_bin_14d\"] = pd.cut(subset_0_730[\"time_to_liq_days\"], bins=edges_14d, right=False, include_lowest=True)\n",
    "sum_14d = subset_0_730.groupby(\"tli_bin_14d\", observed=False).agg(\n",
    "    debt_usd=(\"borrowed_amt_with_interest_usd\",\"sum\"),\n",
    "    accounts=(\"account\",\"count\")\n",
    ").reindex(cats_14d).reset_index(names=\"tli_bin_14d\")\n",
    "sum_14d[\"bin_left\"] = sum_14d[\"tli_bin_14d\"].apply(lambda iv: float(iv.left) if pd.notna(iv) else np.nan)\n",
    "sum_14d[\"bin_width\"] = 14.0\n",
    "sum_14d.to_csv(RESULTS/\"tli_debt_binned_14d_0_730.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(sum_14d[\"bin_left\"], sum_14d[\"debt_usd\"]/1e6, width=sum_14d[\"bin_width\"], align=\"edge\")\n",
    "plt.xlabel(\"Time to liquidation (days, 14-day bins)\")\n",
    "plt.ylabel(\"Debt (USD Millions)\")\n",
    "plt.title(\"Distribution of Debt by Time-to-Liq (0–730 days, 14-day bins)\")\n",
    "plt.tight_layout(); plt.savefig(RESULTS/\"time_to_liq_distribution_0_730_14d.png\"); plt.close()\n",
    "\n",
    "# F) Heatmap: managers × scenarios (Top-15 by -20% liquidations), SOFT COLORS\n",
    "heat = g.copy()\n",
    "for col in [\"liq_flag_5_sum\",\"liq_flag_10_sum\",\"liq_flag_15_sum\",\"liq_flag_20_sum\"]:\n",
    "    if col not in heat.columns: heat[col] = 0\n",
    "heat = heat.sort_values(\"liq_flag_20_sum\", ascending=False).head(15).copy()\n",
    "M = heat[[\"liq_flag_5_sum\",\"liq_flag_10_sum\",\"liq_flag_15_sum\",\"liq_flag_20_sum\"]].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 0.5 + 0.5*len(heat)))\n",
    "im = plt.imshow(M, aspect=\"auto\", cmap=\"Blues\")\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.set_label(\"Liquidations\")\n",
    "plt.xticks([0,1,2,3], [\"-5%\",\"-10%\",\"-15%\",\"-20%\"])\n",
    "plt.yticks(range(len(heat)), [shorten(n, 28, placeholder=\"…\") for n in heat[\"manager_label\"]])\n",
    "\n",
    "for i in range(M.shape[0]):\n",
    "    for j in range(M.shape[1]):\n",
    "        if M[i,j] > 0:\n",
    "            plt.text(j, i, int(M[i,j]), ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
    "\n",
    "plt.title(\"Managers vs Stress Scenarios (Top-15 by -20% liquidations)\")\n",
    "plt.tight_layout(); plt.savefig(RESULTS/\"heatmap_stress.png\"); plt.close()\n",
    "\n",
    "# -------------------------\n",
    "# 7) Scenario CSVs (fallen accounts) + manager increments\n",
    "# -------------------------\n",
    "for s in SCENARIOS:\n",
    "    tag=f\"{int(abs(s)*100)}\"\n",
    "    fallen = df_acc[df_acc[f\"liq_flag_{tag}\"]].copy()\n",
    "    cols = [\"account\",\"manager_label\",\"credit_manager\",\"underlying_symbol\",\n",
    "            \"borrowed_amt_with_interest_usd\",\"hf_raw\",f\"hf_stress_{tag}\",\"time_to_liq_days\"]\n",
    "    existing_cols = [c for c in cols if c in fallen.columns]\n",
    "    fallen[existing_cols].to_csv(RESULTS/f\"fallen_accounts_{tag}.csv\", index=False)\n",
    "\n",
    "g[[\"manager_label\",\"tli_median_days\",\n",
    "   \"liq_flag_5_sum\",\"liq_flag_10_sum\",\"liq_flag_15_sum\",\"liq_flag_20_sum\",\n",
    "   \"incr_10_vs_5\",\"incr_15_vs_10\",\"incr_20_vs_15\"\n",
    "]].to_csv(RESULTS/\"manager_increments.csv\", index=False)\n",
    "\n",
    "# -------------------------\n",
    "# 8) UNDERLYING-ASSET ANALYTICS (group BY readable underlying_symbol)\n",
    "# -------------------------\n",
    "if \"underlying_symbol\" in df_acc.columns:\n",
    "    ua = df_acc.groupby(\"underlying_symbol\", dropna=False).agg(\n",
    "        accounts=(\"account\",\"count\"),\n",
    "        debt_usd_sum=(\"borrowed_amt_with_interest_usd\",\"sum\"),\n",
    "        hf_min=(\"hf_raw\",\"min\"),\n",
    "        hf_median=(\"hf_raw\",\"median\"),\n",
    "        tli_median_days=(\"time_to_liq_days\", lambda x: np.median(x.replace([np.inf, -np.inf], np.nan)))\n",
    "    ).reset_index()\n",
    "\n",
    "    for d in [7,30,90]:\n",
    "        ua[f\"tli_le_{d}_count\"] = (\n",
    "            df_acc.assign(_f=(df_acc[\"time_to_liq_days\"]<=d))\n",
    "                 .groupby(\"underlying_symbol\")[\"_f\"].sum()\n",
    "                 .reindex(ua[\"underlying_symbol\"]).fillna(0).astype(int).values\n",
    "        )\n",
    "\n",
    "    for s in SCENARIOS:\n",
    "        tag = f\"{int(abs(s)*100)}\"\n",
    "        ua[f\"liq_{tag}_count\"] = (\n",
    "            df_acc.groupby(\"underlying_symbol\")[f\"liq_flag_{tag}\"].sum()\n",
    "                 .reindex(ua[\"underlying_symbol\"]).fillna(0).astype(int).values\n",
    "        )\n",
    "        ua[f\"dar_{tag}_usd\"] = (\n",
    "            df_acc.groupby(\"underlying_symbol\")[f\"dar_{tag}_usd\"].sum()\n",
    "                 .reindex(ua[\"underlying_symbol\"]).fillna(0.0).values\n",
    "        )\n",
    "\n",
    "    # --- Underlying-level: add TtL medians under rate shocks + Liq @ -10% ---\n",
    "if \"underlying_symbol\" in df_acc.columns:\n",
    "\n",
    "    ua_rate = (\n",
    "        df_acc.groupby(\"underlying_symbol\", dropna=False)[RATE_TTL_COLS]\n",
    "              .median()\n",
    "              .reset_index()\n",
    "    )\n",
    "    ua = ua.merge(ua_rate, on=\"underlying_symbol\", how=\"left\")\n",
    "\n",
    "    if \"liq_flag_10\" in df_acc.columns:\n",
    "        ua[\"liq_10_count\"] = (\n",
    "            df_acc.groupby(\"underlying_symbol\")[\"liq_flag_10\"]\n",
    "                  .sum()\n",
    "                  .reindex(ua[\"underlying_symbol\"])\n",
    "                  .fillna(0)\n",
    "                  .astype(int)\n",
    "                  .values\n",
    "        )\n",
    "    ua.to_csv(RESULTS/\"underlying_stats.csv\", index=False)\n",
    "\n",
    "    # Top-10 underlyings by debt\n",
    "    ua_top = ua.sort_values(\"debt_usd_sum\", ascending=False).head(10)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    y = np.arange(len(ua_top))\n",
    "    plt.barh(y, ua_top[\"debt_usd_sum\"]/1e6)\n",
    "    for i,v in enumerate(ua_top[\"debt_usd_sum\"]/1e6):\n",
    "        plt.text(v, i, f\"  {v:.1f}M\", va=\"center\", ha=\"left\")\n",
    "    plt.yticks(y, ua_top[\"underlying_symbol\"])\n",
    "    plt.xlabel(\"Debt (USD Millions)\"); plt.title(\"Top-10 Underlyings by Debt\")\n",
    "    plt.tight_layout(); plt.savefig(RESULTS/\"underlying_debt_top10.png\"); plt.close()\n",
    "\n",
    "    # Stress DAR by scenario (stacked bars for softness)\n",
    "    xs = np.arange(len(ua_top))\n",
    "    plt.figure(figsize=(12,6))\n",
    "    base = np.zeros(len(ua_top))\n",
    "    for tag, color in zip([\"5\",\"10\",\"15\",\"20\"], [\"#c6dbef\",\"#9ecae1\",\"#6baed6\",\"#4292c6\"]):  # мягкая сине-голубая гамма\n",
    "        vals = ua_top[f\"dar_{tag}_usd\"]/1e6\n",
    "        plt.bar(xs, vals, bottom=base, label=f\"-{tag}%\", color=color)\n",
    "        base += vals\n",
    "    for i, v in enumerate(base):\n",
    "        if v > 0:\n",
    "            plt.text(xs[i], v, f\"{v:.1f}M\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    plt.xticks(xs, ua_top[\"underlying_symbol\"])\n",
    "    plt.ylabel(\"Debt-at-Risk (USD Millions)\"); plt.title(\"Debt-at-Risk by Underlying (Scenarios)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(RESULTS/\"underlying_dar_scenarios_top10.png\"); plt.close()\n",
    "\n",
    "print(f\"✅ Done. All outputs saved in: {RESULTS.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Heatmap: Underlyings × Stress Scenarios (Liquidations, Top-10 by -20% liqs)\n",
    "# -------------------------\n",
    "if \"underlying_symbol\" in df_acc.columns:\n",
    "    ua_liq = df_acc.groupby(\"underlying_symbol\").agg(\n",
    "        liq_5=(\"liq_flag_5\",\"sum\"),\n",
    "        liq_10=(\"liq_flag_10\",\"sum\"),\n",
    "        liq_15=(\"liq_flag_15\",\"sum\"),\n",
    "        liq_20=(\"liq_flag_20\",\"sum\")\n",
    "    ).reset_index()\n",
    "\n",
    "    ua_liq = ua_liq.sort_values(\"liq_20\", ascending=False).head(10)\n",
    "    H = ua_liq[[\"liq_5\",\"liq_10\",\"liq_15\",\"liq_20\"]].to_numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 0.5 + 0.5*len(ua_liq)))\n",
    "    im = plt.imshow(H, aspect=\"auto\", cmap=\"Blues\")\n",
    "    plt.colorbar(im, label=\"Liquidations\")\n",
    "    plt.xticks(range(H.shape[1]), [\"-5%\",\"-10%\",\"-15%\",\"-20%\"])\n",
    "    plt.yticks(range(len(ua_liq)), ua_liq[\"underlying_symbol\"])\n",
    "    for i in range(H.shape[0]):\n",
    "        for j in range(H.shape[1]):\n",
    "            if H[i,j] > 0:\n",
    "                plt.text(j, i, int(H[i,j]), ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
    "    plt.title(\"Underlyings vs Stress Scenarios (Top-10 by -20% liquidations)\")\n",
    "    plt.tight_layout(); plt.savefig(RESULTS/\"underlying_heatmap_scenarios.png\"); plt.close()\n",
    "\n",
    "# -------------------------\n",
    "# Risk curve: cumulative debt vs TtL threshold (0–90 days)\n",
    "#  — базовая кривая + 4 кривые под шоками ставки (разные цвета)\n",
    "#  — x-ось в днях (стэп-график по каждому дню)\n",
    "#  — точки/подписи только раз в 15 дней: 15,30,45,60,75,90\n",
    "# -------------------------\n",
    "def cum_at_thresholds(ttl_series, debt_series, thresholds):\n",
    "    ttl = pd.to_numeric(ttl_series, errors=\"coerce\").to_numpy()\n",
    "    debt = pd.to_numeric(debt_series, errors=\"coerce\").to_numpy()\n",
    "    mask = np.isfinite(ttl) & np.isfinite(debt) & (ttl >= 0)\n",
    "    ttl = ttl[mask]; debt = debt[mask]\n",
    "    out_debt = []\n",
    "    out_n = []\n",
    "    for t in thresholds:\n",
    "        m = ttl <= t\n",
    "        out_debt.append(debt[m].sum())\n",
    "        out_n.append(int(m.sum()))\n",
    "    return np.array(out_debt), np.array(out_n)\n",
    "\n",
    "CURVES = [(\"Base\", \"time_to_liq_days\", \"#1f77b4\")] + [\n",
    "    (\"Rate +25%\", \"time_to_liq_days__r_p25\", \"#2ca02c\"),\n",
    "    (\"Rate +50%\", \"time_to_liq_days__r_p50\", \"#ff7f0e\"),\n",
    "    (\"Rate ×2\",   \"time_to_liq_days__r_x2\",  \"#d62728\"),\n",
    "    (\"Rate ×4\",   \"time_to_liq_days__r_x4\",  \"#9467bd\"),\n",
    "]\n",
    "\n",
    "thr_full = np.arange(0, 91, 1)    \n",
    "thr_mark = np.arange(0, 91, 10)   \n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for label, col, color in CURVES:\n",
    "    if col not in df_acc.columns:\n",
    "        continue\n",
    "\n",
    "    y_full, _ = cum_at_thresholds(df_acc[col], df_acc[\"borrowed_amt_with_interest_usd\"], thr_full)\n",
    "    plt.step(thr_full, y_full/1e6, where=\"post\", label=label, color=color, linewidth=2)\n",
    "\n",
    "    y_mark, n_mark = cum_at_thresholds(df_acc[col], df_acc[\"borrowed_amt_with_interest_usd\"], thr_mark)\n",
    "    plt.scatter(thr_mark[1:], (y_mark/1e6)[1:], s=22, color=color, zorder=3)\n",
    "    for t, y, n in zip(thr_mark[1:], (y_mark/1e6)[1:], n_mark[1:]):\n",
    "        plt.text(t, y, f\"{y:.1f}M ({n})\", ha=\"left\", va=\"bottom\", fontsize=8, color=color)\n",
    "\n",
    "plt.xlabel(\"TtL threshold (days)\")\n",
    "plt.ylabel(\"Cumulative Debt (USD Millions)\")\n",
    "plt.title(\"Cumulative Debt at Risk vs Time-to-Liq Threshold (0–90 days)\")\n",
    "plt.legend()\n",
    "plt.tight_layout(); plt.savefig(RESULTS/\"risk_curve_cum_debt_0_90.png\"); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ One-pager V2 generated:\n",
      "- HTML: /Users/phlxndr/Desktop/GearBox/September/results/risk_onepager_v2.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q6/s347jm256n93cg0ph4w1dt2r0000gn/T/ipykernel_40849/3126316886.py:83: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  generated = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M UTC\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Paths\n",
    "# ------------------------------------------------------------\n",
    "RESULTS = Path(\"results\")\n",
    "RESULTS.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "OUT_HTML = RESULTS / \"risk_onepager_v2.html\"\n",
    "\n",
    "# Data produced by pipeline\n",
    "MANAGER_STATS     = RESULTS / \"manager_stats.csv\"\n",
    "UNDERLYING_STATS  = RESULTS / \"underlying_stats.csv\"\n",
    "ACCOUNT_STATS     = RESULTS / \"account_stats.csv\"\n",
    "\n",
    "# Figures (we will place them section-wise, ≤2 per row)\n",
    "FIGS = {  # logical sections → list of filenames\n",
    "    \"Stress tests\": [\n",
    "        \"stress_liquidations.png\",\n",
    "        \"risk_curve_cum_debt_0_90.png\",\n",
    "        \"underlying_dar_scenarios_top10.png\",\n",
    "    ],\n",
    "    \"Heatmaps\": [\n",
    "        \"heatmap_stress.png\",\n",
    "        \"underlying_heatmap_scenarios.png\",\n",
    "    ],\n",
    "    \"Managers & Underlyings\": [\n",
    "        \"top10_time_to_liq.png\",\n",
    "        \"underlying_debt_top10.png\",\n",
    "    ],\n",
    "    \"Distributions & Scatters\": [\n",
    "        \"time_to_liq_distribution.png\",\n",
    "        \"time_to_liq_distribution_0_730_14d.png\",\n",
    "        \"scatter_hf_debt.png\",\n",
    "        \"scatter_debt_tli.png\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Only keep existing images\n",
    "for sec, files in list(FIGS.items()):\n",
    "    FIGS[sec] = [RESULTS/f for f in files if (RESULTS/f).exists()]\n",
    "# Remove empty sections\n",
    "FIGS = {sec:paths for sec,paths in FIGS.items() if paths}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load data (robust)\n",
    "# ------------------------------------------------------------\n",
    "def _safe_csv(p):\n",
    "    try:\n",
    "        return pd.read_csv(p)\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "mgr = _safe_csv(MANAGER_STATS)\n",
    "ua  = _safe_csv(UNDERLYING_STATS)\n",
    "acc = _safe_csv(ACCOUNT_STATS)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Helpers\n",
    "# ------------------------------------------------------------\n",
    "def usd(x):\n",
    "    try: return f\"${x:,.0f}\"\n",
    "    except: return str(x)\n",
    "\n",
    "def usd_m(x):\n",
    "    try: return f\"${x/1e6:,.1f}M\"\n",
    "    except: return str(x)\n",
    "\n",
    "generated = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M UTC\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Build richer tables\n",
    "# ------------------------------------------------------------\n",
    "# Manager table: Top 10 by Liq @ -20% (fallback: by Debt), with TtL medians under rate shocks\n",
    "rate_cols_mgr = [c for c in [\"time_to_liq_days__r_p25\",\"time_to_liq_days__r_p50\",\"time_to_liq_days__r_x2\",\"time_to_liq_days__r_x4\"] if c in mgr.columns]\n",
    "base_cols_mgr = [\"manager_label\",\"risky_accounts\",\"tli_median_days\",\"liq_flag_10_sum\",\"liq_flag_20_sum\",\"debt_usd_sum\"]\n",
    "cols_mgr = base_cols_mgr + rate_cols_mgr\n",
    "mgr_view = pd.DataFrame()\n",
    "if not mgr.empty:\n",
    "    sort_key = \"liq_flag_20_sum\" if \"liq_flag_20_sum\" in mgr.columns else (\"debt_usd_sum\" if \"debt_usd_sum\" in mgr.columns else mgr.columns[0])\n",
    "    mgr_view = mgr.sort_values(sort_key, ascending=False)[cols_mgr].head(10).copy()\n",
    "\n",
    "def format_mgr_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty: return df\n",
    "    out = df.copy()\n",
    "    # formats\n",
    "    if \"debt_usd_sum\" in out.columns:\n",
    "        out[\"Debt (USD)\"] = out[\"debt_usd_sum\"].apply(usd_m); out.drop(columns=[\"debt_usd_sum\"], inplace=True)\n",
    "    if \"tli_median_days\" in out.columns:\n",
    "        out[\"Median TtL (d)\"] = out[\"tli_median_days\"].map(lambda v: f\"{float(v):.1f}\" if pd.notna(v) else \"\"); out.drop(columns=[\"tli_median_days\"], inplace=True)\n",
    "    # rate shock medians (rename)\n",
    "    rename_rate = {\n",
    "        \"time_to_liq_days__r_p25\": \"TtL @ Rate +25% (d)\",\n",
    "        \"time_to_liq_days__r_p50\": \"TtL @ Rate +50% (d)\",\n",
    "        \"time_to_liq_days__r_x2\":  \"TtL @ Rate ×2 (d)\",\n",
    "        \"time_to_liq_days__r_x4\":  \"TtL @ Rate ×4 (d)\",\n",
    "    }\n",
    "    for c in rate_cols_mgr:\n",
    "        out[rename_rate[c]] = out[c].map(lambda v: f\"{float(v):.1f}\" if pd.notna(v) else \"\")\n",
    "        out.drop(columns=[c], inplace=True)\n",
    "    out = out.rename(columns={\n",
    "        \"manager_label\":\"Manager\",\n",
    "        \"risky_accounts\":\"Accounts\",\n",
    "        \"liq_flag_10_sum\":\"Liq @ -10%\",\n",
    "        \"liq_flag_20_sum\":\"Liq @ -20%\",\n",
    "    })\n",
    "    # desired order\n",
    "    preferred = [\"Manager\",\"Accounts\",\"Median TtL (d)\",\"TtL @ Rate +25% (d)\",\"TtL @ Rate +50% (d)\",\"TtL @ Rate ×2 (d)\",\"TtL @ Rate ×4 (d)\",\"Liq @ -10%\",\"Liq @ -20%\",\"Debt (USD)\"]\n",
    "    out = out[[c for c in preferred if c in out.columns]]\n",
    "    return out\n",
    "\n",
    "mgr_tbl = format_mgr_table(mgr_view)\n",
    "\n",
    "# Underlying table: Top 10 by Debt, add Liq @ -10% and TtL medians under rate shocks\n",
    "rate_cols_ua = [c for c in [\"time_to_liq_days__r_p25\",\"time_to_liq_days__r_p50\",\"time_to_liq_days__r_x2\",\"time_to_liq_days__r_x4\"] if c in ua.columns]\n",
    "base_cols_ua = [\"underlying_symbol\",\"accounts\",\"debt_usd_sum\",\"liq_10_count\",\"liq_20_count\"]\n",
    "cols_ua = [c for c in base_cols_ua + rate_cols_ua if c in ua.columns]\n",
    "ua_view = pd.DataFrame()\n",
    "if not ua.empty:\n",
    "    sort_key = \"debt_usd_sum\" if \"debt_usd_sum\" in ua.columns else ua.columns[0]\n",
    "    ua_view = ua.sort_values(sort_key, ascending=False)[cols_ua].head(10).copy()\n",
    "\n",
    "def format_ua_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty: return df\n",
    "    out = df.copy()\n",
    "    if \"debt_usd_sum\" in out.columns:\n",
    "        out[\"Debt (USD)\"] = out[\"debt_usd_sum\"].apply(usd_m); out.drop(columns=[\"debt_usd_sum\"], inplace=True)\n",
    "    rename_rate = {\n",
    "        \"time_to_liq_days__r_p25\": \"TtL @ Rate +25% (d)\",\n",
    "        \"time_to_liq_days__r_p50\": \"TtL @ Rate +50% (d)\",\n",
    "        \"time_to_liq_days__r_x2\":  \"TtL @ Rate ×2 (d)\",\n",
    "        \"time_to_liq_days__r_x4\":  \"TtL @ Rate ×4 (d)\",\n",
    "    }\n",
    "    for c in rate_cols_ua:\n",
    "        out[rename_rate[c]] = out[c].map(lambda v: f\"{float(v):.1f}\" if pd.notna(v) else \"\")\n",
    "        out.drop(columns=[c], inplace=True)\n",
    "    out = out.rename(columns={\n",
    "        \"underlying_symbol\":\"Underlying\",\n",
    "        \"accounts\":\"Accounts\",\n",
    "        \"liq_10_count\":\"Liq @ -10%\",\n",
    "        \"liq_20_count\":\"Liq @ -20%\",\n",
    "    })\n",
    "    preferred = [\"Underlying\",\"Accounts\",\"Liq @ -10%\",\"Liq @ -20%\",\"TtL @ Rate +25% (d)\",\"TtL @ Rate +50% (d)\",\"TtL @ Rate ×2 (d)\",\"TtL @ Rate ×4 (d)\",\"Debt (USD)\"]\n",
    "    out = out[[c for c in preferred if c in out.columns]]\n",
    "    return out\n",
    "\n",
    "ua_tbl = format_ua_table(ua_view)\n",
    "\n",
    "# KPI row (from account_stats if available; otherwise rough from mgr)\n",
    "acc_kpi = _safe_csv(ACCOUNT_STATS)\n",
    "def _kpi_lookup(df, key, default=\"—\"):\n",
    "    try:\n",
    "        return df.loc[df[\"metric\"]==key, \"value\"].iloc[0]\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "accounts_total = len(df_acc) if not acc_kpi.empty else (int(mgr[\"risky_accounts\"].sum()) if \"risky_accounts\" in mgr.columns else None)\n",
    "debt_total_usd = float(_kpi_lookup(acc_kpi, \"debt_usd_sum\", default=np.nan)) if not acc_kpi.empty else (float(mgr[\"debt_usd_sum\"].sum()) if \"debt_usd_sum\" in mgr.columns else np.nan)\n",
    "hf_min     = float(_kpi_lookup(acc_kpi, \"hf_p10\", default=np.nan)) if False else (float(mgr[\"hf_min\"].min()) if (\"hf_min\" in mgr.columns and len(mgr)) else np.nan)\n",
    "hf_median  = float(_kpi_lookup(acc_kpi, \"hf_p50\", default=np.nan)) if not acc_kpi.empty else (float(mgr[\"hf_median\"].median()) if (\"hf_median\" in mgr.columns and len(mgr)) else np.nan)\n",
    "tli_median = float(_kpi_lookup(acc_kpi, \"tli_days_p50\", default=np.nan)) if not acc_kpi.empty else (float(mgr[\"tli_median_days\"].median()) if (\"tli_median_days\" in mgr.columns and len(mgr)) else np.nan)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# HTML (≤2 charts per row)\n",
    "# ------------------------------------------------------------\n",
    "def _html_table(df: pd.DataFrame, title: str) -> str:\n",
    "    if df is None or df.empty:\n",
    "        return f'<div class=\"card\"><h3>{title}</h3><p><em>No data</em></p></div>'\n",
    "    cols = list(df.columns)\n",
    "    head = \"\".join([f\"<th>{c}</th>\" for c in cols])\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        rows.append(\"<tr>\" + \"\".join([f\"<td>{r[c]}</td>\" for c in cols]) + \"</tr>\")\n",
    "    return f\"\"\"\n",
    "    <div class=\"card\">\n",
    "      <h3>{title}</h3>\n",
    "      <table>\n",
    "        <thead><tr>{head}</tr></thead>\n",
    "        <tbody>{''.join(rows)}</tbody>\n",
    "      </table>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "def _html_img(path: Path) -> str:\n",
    "    return f'<div class=\"card\"><img src=\"{path.name}\" alt=\"{path.name}\"/></div>'\n",
    "\n",
    "html_sections = []\n",
    "# Header + KPI\n",
    "html_header = f\"\"\"\n",
    "<h1>Low-HF Risks</h1>\n",
    "<div class=\"subtle\">Generated {generated}</div>\n",
    "<div class=\"kpi\">\n",
    "  <div class=\"pill\"><b>Total Accounts</b><br>{accounts_total if accounts_total is not None else '—'}</div>\n",
    "  <div class=\"pill\"><b>Total Debt</b><br>{usd(debt_total_usd) if not np.isnan(debt_total_usd) else '—'}</div>\n",
    "  <div class=\"pill\"><b>HF min</b><br>{('—' if np.isnan(hf_min) else f'{hf_min:.3f}')}</div>\n",
    "  <div class=\"pill\"><b>HF median</b><br>{('—' if np.isnan(hf_median) else f'{hf_median:.3f}')}</div>\n",
    "  <div class=\"pill\"><b>Median TtL</b><br>{('—' if np.isnan(tli_median) else f'{tli_median:.1f} d')}</div>\n",
    "</div>\n",
    "\"\"\"\n",
    "html_sections.append(html_header)\n",
    "\n",
    "# Tables section\n",
    "html_tables = f\"\"\"\n",
    "<h2>Key Tables</h2>\n",
    "<div class=\"grid2\">\n",
    "  {_html_table(mgr_tbl, \"Top Managers (by -20% liquidations)\") if not mgr_tbl.empty else _html_table(pd.DataFrame(), \"Top Managers\")}\n",
    "  {_html_table(ua_tbl,  \"Top Underlyings (by Debt)\") if not ua_tbl.empty else _html_table(pd.DataFrame(), \"Top Underlyings\")}\n",
    "</div>\n",
    "<p class=\"note\">Rate shock TtL columns show median time-to-liquidation if borrow APY rises by +25%, +50%, ×2, ×4.</p>\n",
    "\"\"\"\n",
    "html_sections.append(html_tables)\n",
    "\n",
    "# Charts, by sections\n",
    "for sec, paths in FIGS.items():\n",
    "    if not paths: continue\n",
    "    rows = []\n",
    "    row = []\n",
    "    for p in paths:\n",
    "        row.append(_html_img(p))\n",
    "        if len(row) == 2:\n",
    "            rows.append(f\"<div class='grid2'>{''.join(row)}</div>\")\n",
    "            row = []\n",
    "    if row:\n",
    "        rows.append(f\"<div class='grid2'>{''.join(row)}</div>\")\n",
    "    html_sections.append(f\"<h2>{sec}</h2>\" + \"\\n\".join(rows))\n",
    "\n",
    "# Combine HTML\n",
    "html = f\"\"\"\n",
    "<html>\n",
    "<head>\n",
    "  <meta charset=\"utf-8\"/>\n",
    "  <title>Risk One-Pager V2</title>\n",
    "  <style>\n",
    "    body {{ font-family: Arial, Helvetica, sans-serif; margin: 24px; color: #111; }}\n",
    "    h1 {{ margin: 0 0 8px 0; }}\n",
    "    h2 {{ margin: 18px 0 8px 0; }}\n",
    "    h3 {{ margin: 0 0 6px 0; font-size: 14px; }}\n",
    "    .subtle {{ color: #666; font-size: 12px; }}\n",
    "    .note {{ color: #666; font-size: 12px; margin-top: 6px; }}\n",
    "    .kpi {{ display: flex; gap: 14px; flex-wrap: wrap; margin: 10px 0 16px 0; }}\n",
    "    .pill {{ border: 1px solid #e3e3e3; border-radius: 12px; padding: 10px 12px; min-width: 170px; box-shadow: 0 1px 2px rgba(0,0,0,0.04); }}\n",
    "    .grid2 {{ display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 14px; }}\n",
    "    .card {{ border: 1px solid #eee; border-radius: 10px; padding: 8px; background: #fff; }}\n",
    "    img {{ width: 100%; height: auto; display: block; border-radius: 6px; }}\n",
    "    table {{ border-collapse: collapse; width: 100%; font-size: 13px; }}\n",
    "    th, td {{ border: 1px solid #e6e6e6; padding: 6px 8px; text-align: left; }}\n",
    "    th {{ background: #fafafa; }}\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  {''.join(html_sections)}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "OUT_HTML.write_text(html, encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ One-pager V2 generated:\")\n",
    "print(f\"- HTML: {OUT_HTML.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gbx-root-venv)",
   "language": "python",
   "name": "gbx-root-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
